{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python transformers accelerate\n",
    "from diffusers import StableDiffusionPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\"\n",
    ")\n",
    "\n",
    "# speed up diffusion process with faster scheduler and memory optimization\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "generator = torch.manual_seed(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet2DConditionModel \n",
    "statedictpipe=pipe.unet.state_dict()\n",
    "new_unet=UNet2DConditionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unet.load_state_dict(statedictpipe)\n",
    "pipe.unet=new_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptp_utils_text as ptp_utils\n",
    "def run_and_display(pipe,prompts, negative_prompts, latent=None, run_baseline=False, generator=None,   results_dir='results'):\n",
    "\n",
    "    images, x_t, all_list_encoder, all_list_decoder= ptp_utils.text2image_ldm_stable(pipe, prompts, negative_prompts, latent=latent, num_inference_steps=50, guidance_scale=7.5, generator=generator,low_resource=False)\n",
    "\n",
    "    # ptp_utils.view_images(images,results_dir=results_dir)\n",
    "    return images, x_t, all_list_encoder, all_list_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts=[\"An astronaut riding an horse\"]\n",
    "negative_prompts=[\"Bad quality, bad anatomy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nump\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "def save_image(imagea, loc):\n",
    "    # if image.shape[1]>=64:\n",
    "        imagea=imagea-imagea.min()\n",
    "        imagea=imagea/imagea.max()\n",
    "        imagea = imagea[0].cpu().cpu().numpy()\n",
    "        # image=(image-np.min(image))(np.max(image)-np.min(image))\n",
    "        imagea = (imagea * 255).astype(np.uint8)\n",
    "        imagea=Image.fromarray(imagea)\n",
    "        imagea=imagea.resize((256,256))\n",
    "        image_array = np.array(imagea)\n",
    "        print(np.shape(image_array))\n",
    "        print(loc)\n",
    "        # Create a heatmap from the array\n",
    "        plt.imshow(image_array, cmap='viridis')\n",
    "\n",
    "        # Remove axes and save the heatmap\n",
    "        plt.axis('off')\n",
    "        plt.savefig(loc, bbox_inches='tight', pad_inches=0)\n",
    "        return imagea\n",
    "    # return None\n",
    "    # return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(\"cuda\")\n",
    "# g_cpu = torch.Generator().manual_seed(24)\n",
    "# latent = torch.randn(\n",
    "#                 (1, 4,512 // 8, 512 // 8),\n",
    "#                 generator=g_cpu,\n",
    "#             )\n",
    "a,b,c,d=run_and_display(pipe,prompts, negative_prompts, latent=None, run_baseline=False, generator=None,  results_dir='results')\n",
    "ptp_utils.view_images(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(len(c))\n",
    "count=0\n",
    "for list1 in c:\n",
    "    count=count+1\n",
    "    for list2 in list1:\n",
    "        print(list2.shape,count)\n",
    "        location='textvar_encoder'\n",
    "        if os.path.exists(location)==False:\n",
    "            os.makedirs(location)\n",
    "        dirname=len(os.listdir(location))\n",
    "        loc=os.path.join(location, str(dirname)+'.png')\n",
    "        # image.save(os.path.join()\n",
    "        image=save_image(list2, loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for list1 in d:\n",
    "    count=count+1\n",
    "    for list2 in list1:\n",
    "        print(list2.shape,count)\n",
    "        location='textvar_decoder'\n",
    "        if os.path.exists(location)==False:\n",
    "            os.makedirs(location)\n",
    "        dirname=len(os.listdir('/media/labuser/sdb/Controlpromptediting/diffscaler_multimodal/'+location))\n",
    "        loc=os.path.join('/media/labuser/sdb/Controlpromptediting/diffscaler_multimodal/'+location, str(dirname)+'.png')\n",
    "        # image.save(os.path.join()\n",
    "        image=save_image(list2, loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusers_freeu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
